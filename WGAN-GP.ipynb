{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e8016-4f25-40d3-9902-bef1ab99cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from time import perf_counter\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# preserve threads for GPU\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "\n",
    "# constrain VRAM usage\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# enable mixed-precision training\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9c260-c6be-4283-8cbf-d99bd8ce6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, length):\n",
    "    predictions = (model.random_generate(length**2).numpy().reshape(-1, 28, 28) + 1.) / 2\n",
    "    plt.figure(figsize=(length, length))\n",
    "    for i in range(length**2):\n",
    "        plt.subplot(length, length, i+1)\n",
    "        plt.imshow(predictions[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_history(history):\n",
    "    plt.plot(history['crit_loss'], label='Critic Loss')\n",
    "    plt.plot(history['gen_loss'], label='Generator Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc564b-bd68-48ab-9f10-f48e7e4c0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_GP:\n",
    "    def __init__(self, crit, gen, crit_opt, gen_opt, z_dim=64, crit_repeat=5, gp_weight=10.):\n",
    "        self.crit = crit\n",
    "        self.gen = gen\n",
    "        self.crit_opt = crit_opt\n",
    "        self.gen_opt = gen_opt\n",
    "        self.z_dim = z_dim\n",
    "        self.crit_repeat = crit_repeat\n",
    "        self.gp_weight = gp_weight\n",
    "        self.history = {'crit_loss':[], 'gen_loss':[]}\n",
    "        self.crit_mean_loss = keras.metrics.Mean(name='crit_loss')\n",
    "        self.gen_mean_loss = keras.metrics.Mean(name='gen_loss')\n",
    "    \n",
    "    def random_generate(self, n_images):\n",
    "        noise = tf.random.normal([n_images, self.z_dim])\n",
    "        return self.gen(noise, training=False)\n",
    "    \n",
    "    def gradient_penalty(self, real, fake):\n",
    "        batch_size = real.shape[0]\n",
    "        epsilon = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        fused = epsilon*real + (1 - epsilon)*fake\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(fused)\n",
    "            crit_fused_pred = self.crit(fused)\n",
    "        gradients = tf.reshape(gp_tape.gradient(crit_fused_pred, fused), [batch_size, -1])\n",
    "        penalty = tf.reduce_mean((tf.norm(gradients, axis=-1) - 1.0)**2)\n",
    "        return penalty\n",
    "    \n",
    "    # execute in graph mode with XLA for superior performance\n",
    "    @tf.function(jit_compile=True)\n",
    "    def train_step(self, real):\n",
    "        batch_size = real.shape[0]\n",
    "        for _ in range(self.crit_repeat):\n",
    "            noise = tf.random.normal([batch_size, self.z_dim])\n",
    "            fake = self.gen(noise, training=False)\n",
    "            concatenated = tf.concat((fake, real), axis=0)\n",
    "            with tf.GradientTape() as crit_tape:\n",
    "                crit_concatenated_pred = self.crit(concatenated)\n",
    "                penalty = self.gradient_penalty(real, fake)\n",
    "                crit_loss = tf.reduce_mean(crit_concatenated_pred[:batch_size]) - \\\n",
    "                    tf.reduce_mean(crit_concatenated_pred[batch_size:]) + self.gp_weight*penalty\n",
    "            grad_of_crit = crit_tape.gradient(crit_loss, self.crit.trainable_variables)\n",
    "            self.crit_opt.apply_gradients(zip(grad_of_crit, self.crit.trainable_variables))\n",
    "            self.crit_mean_loss.update_state(crit_loss)\n",
    "        noise = tf.random.normal([batch_size, self.z_dim])\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake = self.gen(noise)\n",
    "            crit_fake_pred = self.crit(fake, training=False)\n",
    "            gen_loss = -tf.reduce_mean(crit_fake_pred)\n",
    "        grad_of_gen = gen_tape.gradient(gen_loss, self.gen.trainable_variables)\n",
    "        self.gen_opt.apply_gradients(zip(grad_of_gen, self.gen.trainable_variables))\n",
    "        self.gen_mean_loss.update_state(gen_loss)\n",
    "    \n",
    "    def fit(self, data, epochs=1):\n",
    "        for epoch in range(epochs):\n",
    "            tic = perf_counter()\n",
    "            self.crit_mean_loss.reset_states()\n",
    "            self.gen_mean_loss.reset_states()\n",
    "            for real in tqdm(data):\n",
    "                model.train_step(real)\n",
    "            self.history['crit_loss'].append(self.crit_mean_loss.result().numpy())\n",
    "            self.history['gen_loss'].append(self.gen_mean_loss.result().numpy())\n",
    "            display.clear_output(wait=True)\n",
    "            print(\"Epoch %d/%d - %.1fs | crit_loss: %.5f - gen_loss: %.5f\"%(\n",
    "                epoch+1, EPOCHS, perf_counter() - tic, self.history['crit_loss'][-1], self.history['gen_loss'][-1]))\n",
    "            test_model(self, 4)\n",
    "            show_history(self.history)\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9333135-0eb4-47d3-bdff-31f89e82affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUFFER=70000\n",
    "BATCH_SIZE=64\n",
    "EPOCHS = 50\n",
    "DIMS = (28, 28, 1)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "z_dim = 64\n",
    "crit_repeat = 5\n",
    "gp_weight = 10.\n",
    "lr = 1e-4\n",
    "beta_1 = 0.\n",
    "beta_2 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1851c-ee3c-40ce-b8ad-76ee58230f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "X = np.concatenate((x_train, x_test)).astype(np.float32).reshape(-1, 28, 28, 1) / 127.5 - 1.\n",
    "dataloader = tf.data.Dataset.from_tensor_slices(X).shuffle(TRAIN_BUFFER).batch(\n",
    "    BATCH_SIZE, num_parallel_calls=AUTOTUNE, deterministic=False, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "\n",
    "critic = keras.Sequential([\n",
    "    layers.InputLayer(DIMS), \n",
    "    layers.Conv2D(32, 4, strides=2, padding='same', use_bias=False),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    layers.Conv2D(64, 4, strides=2, padding='same', use_bias=False),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    layers.Conv2D(128, 3, strides=1, padding='same', use_bias=False),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, dtype=tf.float32)\n",
    "])\n",
    "\n",
    "generator = keras.Sequential([\n",
    "    layers.InputLayer([z_dim]),\n",
    "    layers.Dense(7*7*128, use_bias=False),\n",
    "    layers.Reshape([7, 7, 128]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2DTranspose(64, 4, strides=2, padding='same', use_bias=False),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2DTranspose(32, 4, strides=2, padding='same', use_bias=False),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "\n",
    "    layers.Conv2D(1, 3, strides=1, padding='same', activation='tanh', dtype=tf.float32)\n",
    "])\n",
    "\n",
    "model = WGAN_GP(\n",
    "    crit=critic,\n",
    "    gen=generator,\n",
    "    crit_opt=keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2),\n",
    "    gen_opt=keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2),\n",
    "    z_dim=z_dim,\n",
    "    crit_repeat=crit_repeat,\n",
    "    gp_weight=gp_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e33f96-37e8-4a4c-ba53-d047172fe627",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataloader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab463e4-50de-4c7d-88da-f08fce89ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4200f-d433-4c63-8d02-294ddde2509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = \"./WGAN_GP\"\n",
    "#model.gen.save(model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357e15a-cde1-46ee-9910-a1e1b72df625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model_path = \"./WGAN_GP\"\n",
    "loaded_model = WGAN_GP(\n",
    "    gen=keras.models.load_model(model_path, compile=False),\n",
    "    crit=None,\n",
    "    gen_opt=None,\n",
    "    crit_opt=None,\n",
    "    z_dim=64,\n",
    "    gp_weight=10.,\n",
    "    crit_repeat=5\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5d602-8c26-479a-9b61-e5af93f1fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model(loaded_model, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b4c1e-19c2-4b3f-83fc-cfd7a090e2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
